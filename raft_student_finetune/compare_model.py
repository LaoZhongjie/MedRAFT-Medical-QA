"""
compare_models.py
éšæœºä» teacher_dataset.json ä¸­æŠ½å– 100 æ¡æ ·æœ¬ï¼Œ
æ¯”è¾ƒåŸºç¡€æ¨¡å‹ä¸å¾®è°ƒæ¨¡å‹çš„å›ç­”ï¼Œå¹¶ä¿å­˜ç»“æœåˆ° JSON æ–‡ä»¶ã€‚
"""

import json
import random
import os
from datetime import datetime
from inference import RAFTInference
from model import load_trained_model, load_base_model
from config import ModelConfig, InferenceConfig

import warnings
warnings.filterwarnings("ignore", message="Failed to load image Python extension")

def load_random_samples(json_path: str, sample_size: int = 100):
    """ä»æ•°æ®é›†ä¸­éšæœºæŠ½å–æ ·æœ¬"""
    print(f"ğŸ“‚ æ­£åœ¨åŠ è½½æ•°æ®é›†: {json_path}")
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    if not isinstance(data, list):
        raise ValueError("teacher_dataset.json å¿…é¡»æ˜¯ä¸€ä¸ªåŒ…å«å¤šä¸ªæ ·æœ¬çš„åˆ—è¡¨")

    if len(data) < sample_size:
        print(f"âš ï¸ æ•°æ®é›†æ ·æœ¬æ•° ({len(data)}) å°‘äº {sample_size}ï¼Œå°†å…¨éƒ¨ä½¿ç”¨ã€‚")
        sample_size = len(data)

    samples = random.sample(data, sample_size)
    print(f"âœ… å·²éšæœºæŠ½å– {sample_size} æ¡æ ·æœ¬è¿›è¡Œå¯¹æ¯”æµ‹è¯•\n")
    return samples


from tqdm import tqdm

def compare_models(base_model_path, fine_tuned_path, test_cases):
    """å¯¹æ¯”åŸºç¡€æ¨¡å‹å’Œå¾®è°ƒæ¨¡å‹è¾“å‡ºï¼Œå¸¦è¿›åº¦æ¡"""
    
    # åŠ è½½åŸºç¡€æ¨¡å‹
    print("ğŸ”§ åŠ è½½åŸºç¡€æ¨¡å‹...")
    base_model_config = ModelConfig(model_name_or_path=base_model_path)
    base_model, base_tokenizer = load_base_model(base_model_path, base_model_config)
    
    # åŠ è½½å¾®è°ƒæ¨¡å‹
    print("ğŸ”§ åŠ è½½å¾®è°ƒæ¨¡å‹...")
    tuned_model_config = ModelConfig(model_name_or_path=fine_tuned_path)
    tuned_model, tuned_tokenizer = load_trained_model(fine_tuned_path, tuned_model_config)
    
    # åˆ›å»ºæ¨ç†å™¨
    inference_config = InferenceConfig(max_new_tokens=1024, temperature=0.7, top_p=0.9)
    base_inferencer = RAFTInference(base_model, base_tokenizer, inference_config)
    tuned_inferencer = RAFTInference(tuned_model, tuned_tokenizer, inference_config)
    
    results = []
    
    # tqdm è¿›åº¦æ¡
    for i, case in enumerate(tqdm(test_cases, desc="ğŸ”„ å¤„ç†æµ‹è¯•æ ·æœ¬", unit="sample"), 1):
        print(f"\n{'='*60}")
        print(f"ğŸ§  æµ‹è¯•æ ·æœ¬ {i}/{len(test_cases)}: {case['question'][:80]}...")
        print(f"{'='*60}")
        
        # åŸºç¡€æ¨¡å‹å›ç­”
        print("ğŸ¤– åŸºç¡€æ¨¡å‹å›ç­”ä¸­...")
        base_resp = base_inferencer.generate(case['question'], case['documents'])
        # print(base_resp)
        
        # å¾®è°ƒæ¨¡å‹å›ç­”
        print("ğŸ¯ å¾®è°ƒæ¨¡å‹å›ç­”ä¸­...")
        tuned_resp = tuned_inferencer.generate(case['question'], case['documents'])
        # print(tuned_resp)
        
        result_item = {
            "id": case.get("id", f"sample_{i}"),
            "question": case["question"],
            "base_response": base_resp,
            "tuned_response": tuned_resp,
            "teacher_answer": case.get("teacher_answer", ""),
            "documents": case.get("documents", [])
        }
        results.append(result_item)
    
    return results


def save_results(results, output_dir="results"):
    """ä¿å­˜å¯¹æ¯”ç»“æœ"""
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, f"compare_results.json")

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ å¯¹æ¯”ç»“æœå·²ä¿å­˜è‡³: {output_path}")
    return output_path


if __name__ == "__main__":
    dataset_path = "teacher_dataset.json"
    base_model_path = "Qwen/Qwen2.5-7B-Instruct"
    fine_tuned_path = "./output/final_model"

    # 1. åŠ è½½éšæœºæ ·æœ¬
    test_samples = load_random_samples(dataset_path, sample_size=50)

    # 2. å¯¹æ¯”æ¨ç†
    results = compare_models(base_model_path, fine_tuned_path, test_samples)

    # 3. ä¿å­˜ç»“æœ
    save_results(results)
