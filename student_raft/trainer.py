"""
è®­ç»ƒå™¨æ¨¡å—
å°è£…è®­ç»ƒé€»è¾‘å’Œå›è°ƒå‡½æ•°
"""
import os
import torch
import json
import numpy as np
from datetime import datetime
from transformers import (
    Trainer,
    TrainingArguments,
    TrainerCallback,
    TrainerState,
    TrainerControl
)
from typing import Dict, Optional, List
from config import TrainingConfig


class TrainingRecorder:
    """è®­ç»ƒè®°å½•å™¨ï¼Œç”¨äºä¿å­˜è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§æŒ‡æ ‡"""
    
    def __init__(self, output_dir: str):
        self.output_dir = output_dir
        self.metrics_file = os.path.join(output_dir, "training_metrics.json")
        self.metrics_history = {
            "train_loss": [],
            "eval_loss": [],
            "learning_rate": [],
            "epoch": [],
            "step": [],
            "timestamp": []
        }
        self.start_time = datetime.now()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
    
    def record_step(self, metrics: Dict, step: int, epoch: float):
        """è®°å½•è®­ç»ƒæ­¥éª¤çš„æŒ‡æ ‡"""
        current_time = datetime.now()
        
        # è®°å½•åŸºç¡€æŒ‡æ ‡
        self.metrics_history["step"].append(step)
        self.metrics_history["epoch"].append(epoch)
        self.metrics_history["timestamp"].append(current_time.isoformat())
        
        # è®°å½•è®­ç»ƒæŸå¤±
        if "loss" in metrics:
            self.metrics_history["train_loss"].append(metrics["loss"])
        else:
            self.metrics_history["train_loss"].append(None)
        
        # è®°å½•è¯„ä¼°æŸå¤±
        if "eval_loss" in metrics:
            self.metrics_history["eval_loss"].append(metrics["eval_loss"])
        else:
            self.metrics_history["eval_loss"].append(None)
        
        # è®°å½•å­¦ä¹ ç‡
        if "learning_rate" in metrics:
            self.metrics_history["learning_rate"].append(metrics["learning_rate"])
        else:
            self.metrics_history["learning_rate"].append(None)
    
    def save_metrics(self):
        """ä¿å­˜æŒ‡æ ‡åˆ°æ–‡ä»¶"""
        with open(self.metrics_file, 'w', encoding='utf-8') as f:
            json.dump(self.metrics_history, f, indent=2, ensure_ascii=False)
        print(f"âœ“ è®­ç»ƒæŒ‡æ ‡å·²ä¿å­˜åˆ°: {self.metrics_file}")
    
    def get_summary(self) -> Dict:
        """è·å–è®­ç»ƒæ‘˜è¦"""
        train_losses = [x for x in self.metrics_history["train_loss"] if x is not None]
        eval_losses = [x for x in self.metrics_history["eval_loss"] if x is not None]
        
        summary = {
            "total_steps": len(self.metrics_history["step"]),
            "training_time": str(datetime.now() - self.start_time),
            "start_time": self.start_time.isoformat(),
            "end_time": datetime.now().isoformat(),
            "min_train_loss": min(train_losses) if train_losses else None,
            "min_eval_loss": min(eval_losses) if eval_losses else None,
            "final_train_loss": train_losses[-1] if train_losses else None,
            "final_eval_loss": eval_losses[-1] if eval_losses else None,
        }
        return summary


def create_training_arguments(training_config: TrainingConfig) -> TrainingArguments:
    """
    åˆ›å»ºè®­ç»ƒå‚æ•°
    
    Args:
        training_config: è®­ç»ƒé…ç½®
        
    Returns:
        TrainingArguments
    """
    args = TrainingArguments(
        output_dir=training_config.output_dir,
        num_train_epochs=training_config.num_train_epochs,
        per_device_train_batch_size=training_config.per_device_train_batch_size,
        per_device_eval_batch_size=training_config.per_device_eval_batch_size,
        gradient_accumulation_steps=training_config.gradient_accumulation_steps,
        learning_rate=training_config.learning_rate,
        warmup_ratio=training_config.warmup_ratio,
        weight_decay=training_config.weight_decay,
        max_grad_norm=training_config.max_grad_norm,
        
        # ä¼˜åŒ–å™¨
        optim=training_config.optim,
        lr_scheduler_type=training_config.lr_scheduler_type,
        
        # ä¿å­˜ç­–ç•¥
        save_strategy=training_config.save_strategy,
        save_steps=training_config.save_steps,
        save_total_limit=training_config.save_total_limit,
        
        # æ—¥å¿—
        logging_steps=training_config.logging_steps,
        logging_dir=os.path.join(training_config.output_dir, 'logs'),
        
        # è¯„ä¼°
        eval_strategy=training_config.eval_strategy,
        eval_steps=training_config.eval_steps,
        
        # ç²¾åº¦
        bf16=training_config.bf16,
        fp16=training_config.fp16,
        
        # å…¶ä»–
        gradient_checkpointing=training_config.gradient_checkpointing,
        dataloader_num_workers=training_config.dataloader_num_workers,
        report_to=training_config.report_to,
        load_best_model_at_end=training_config.load_best_model_at_end,
        metric_for_best_model=training_config.metric_for_best_model,
        greater_is_better=training_config.greater_is_better,
        seed=training_config.seed,
        
        # å…¶ä»–é‡è¦å‚æ•°
        remove_unused_columns=False,
        ddp_find_unused_parameters=False if torch.cuda.device_count() > 1 else None,
        
        # å¯ç”¨è¯¦ç»†æ—¥å¿—è®°å½•
        logging_strategy="steps",
        eval_accumulation_steps=1,
        prediction_loss_only=False,
    )
    
    return args


class CustomCallback(TrainerCallback):
    """è‡ªå®šä¹‰è®­ç»ƒå›è°ƒ"""
    
    def __init__(self, output_dir: str):
        self.best_eval_loss = float('inf')
        self.best_model_checkpoint = None
        self.recorder = TrainingRecorder(output_dir)
        self.current_epoch = 0
        
    def on_log(self, args, state: TrainerState, control: TrainerControl, logs=None, **kwargs):
        """æ—¥å¿—å›è°ƒ"""
        if logs is not None:
            # è®°å½•æŒ‡æ ‡
            self.recorder.record_step(logs, state.global_step, state.epoch)
            
            # æ‰“å°å…³é”®æŒ‡æ ‡
            if 'loss' in logs:
                print(f"Step {state.global_step}: train_loss={logs['loss']:.4f}")
            if 'eval_loss' in logs:
                eval_loss = logs['eval_loss']
                print(f"Step {state.global_step}: eval_loss={eval_loss:.4f}")
                
                # è®°å½•æœ€ä½³æ¨¡å‹
                if eval_loss < self.best_eval_loss:
                    self.best_eval_loss = eval_loss
                    self.best_model_checkpoint = f"checkpoint-{state.global_step}"
                    print(f"  âœ“ æ–°çš„æœ€ä½³æ¨¡å‹! (eval_loss: {eval_loss:.4f})")
            
            # å®šæœŸä¿å­˜æŒ‡æ ‡
            if state.global_step % args.logging_steps == 0:
                self.recorder.save_metrics()
    
    def on_epoch_begin(self, args, state: TrainerState, control: TrainerControl, **kwargs):
        """epochå¼€å§‹å›è°ƒ"""
        self.current_epoch = state.epoch
        print(f"\nğŸ å¼€å§‹ç¬¬ {state.epoch:.1f} è½®è®­ç»ƒ")
    
    def on_epoch_end(self, args, state: TrainerState, control: TrainerControl, **kwargs):
        """epochç»“æŸå›è°ƒ"""
        print(f"âœ… ç¬¬ {state.epoch:.1f} è½®è®­ç»ƒå®Œæˆ")
        # æ¯ä¸ªepochç»“æŸæ—¶ä¿å­˜æŒ‡æ ‡
        self.recorder.save_metrics()
    
    def on_train_begin(self, args, state: TrainerState, control: TrainerControl, **kwargs):
        """è®­ç»ƒå¼€å§‹å›è°ƒ"""
        print("\n" + "="*60)
        print("å¼€å§‹è®­ç»ƒ")
        print("="*60)
        print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
        print(f"è®­ç»ƒè½®æ•°: {args.num_train_epochs}")
        print(f"Batch size: {args.per_device_train_batch_size}")
        print(f"æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: {args.gradient_accumulation_steps}")
        print(f"æœ‰æ•ˆbatch size: {args.per_device_train_batch_size * args.gradient_accumulation_steps * args.world_size}")
        print(f"å­¦ä¹ ç‡: {args.learning_rate}")
        print("="*60 + "\n")
        
        # ä¿å­˜è®­ç»ƒé…ç½®
        config_info = {
            "training_start": datetime.now().isoformat(),
            "output_dir": args.output_dir,
            "num_train_epochs": args.num_train_epochs,
            "per_device_train_batch_size": args.per_device_train_batch_size,
            "gradient_accumulation_steps": args.gradient_accumulation_steps,
            "learning_rate": args.learning_rate,
            "warmup_ratio": args.warmup_ratio,
            "weight_decay": args.weight_decay,
        }
        
        config_file = os.path.join(args.output_dir, "training_config.json")
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config_info, f, indent=2, ensure_ascii=False)
    
    def on_train_end(self, args, state: TrainerState, control: TrainerControl, **kwargs):
        """è®­ç»ƒç»“æŸå›è°ƒ"""
        print("\n" + "="*60)
        print("è®­ç»ƒå®Œæˆ!")
        print("="*60)
        print(f"æ€»æ­¥æ•°: {state.global_step}")
        print(f"æœ€ä½³eval_loss: {self.best_eval_loss:.4f}")
        if self.best_model_checkpoint:
            print(f"æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹: {self.best_model_checkpoint}")
        
        # ä¿å­˜æœ€ç»ˆæŒ‡æ ‡å’Œæ‘˜è¦
        self.recorder.save_metrics()
        summary = self.recorder.get_summary()
        
        summary_file = os.path.join(args.output_dir, "training_summary.json")
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"è®­ç»ƒæ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")
        print("="*60 + "\n")
    
    def on_save(self, args, state: TrainerState, control: TrainerControl, **kwargs):
        """ä¿å­˜å›è°ƒ"""
        checkpoint_folder = f"checkpoint-{state.global_step}"
        print(f"ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_folder}")


class RAFTTrainer(Trainer):
    """è‡ªå®šä¹‰RAFTè®­ç»ƒå™¨"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.training_history = {
            "train_loss": [],
            "eval_loss": [],
            "learning_rate": []
        }
    
    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):
        """
        è®¡ç®—æŸå¤±ï¼Œå¢å¼ºç¨³å®šæ€§å’ŒNaNå¤„ç†
        """
        try:
            # æ£€æŸ¥è¾“å…¥æ•°æ®
            if torch.isnan(inputs['input_ids']).any() or torch.isinf(inputs['input_ids']).any():
                print("âŒ è¾“å…¥æ•°æ®åŒ…å«NaNæˆ–Inf")
                return self._create_safe_loss(inputs)
            
            # æ£€æŸ¥æœ‰æ•ˆlabelsæ•°é‡
            valid_labels = (inputs['labels'] != -100).sum().item()
            if valid_labels < 5:  # å¦‚æœæœ‰æ•ˆæ ‡ç­¾å¤ªå°‘
                print(f"âš ï¸ æœ‰æ•ˆlabelsè¿‡å°‘: {valid_labels}, ä½¿ç”¨å®‰å…¨æŸå¤±")
                return self._create_safe_loss(inputs)
            
            # æ­£å¸¸å‰å‘ä¼ æ’­
            outputs = model(**inputs)
            loss = outputs.loss
            
            # æ£€æŸ¥NaN loss
            if torch.isnan(loss) or torch.isinf(loss):
                print("âš ï¸ æ£€æµ‹åˆ°NaN/Inf loss! åˆ†æåŸå› ...")
                print(f"  æœ‰æ•ˆlabels: {valid_labels}")
                print(f"  input_idsèŒƒå›´: [{inputs['input_ids'].min()}, {inputs['input_ids'].max()}]")
                print(f"  labelsä¸­-100æ•°é‡: {(inputs['labels'] == -100).sum().item()}")
                
                # å°è¯•æ¢¯åº¦è£å‰ªå’Œé‡æ–°è®¡ç®—
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                return self._create_safe_loss(inputs)
            
            return (loss, outputs) if return_outputs else loss
            
        except Exception as e:
            print(f"âŒ æŸå¤±è®¡ç®—å¼‚å¸¸: {e}")
            return self._create_safe_loss(inputs)

    def _create_safe_loss(self, inputs):
        """åˆ›å»ºå®‰å…¨çš„æŸå¤±å€¼"""
        return torch.tensor(0.1, requires_grad=True).to(inputs['input_ids'].device)


def create_trainer(
    model,
    tokenizer,
    train_dataset,
    eval_dataset,
    training_config: TrainingConfig,
    data_collator=None
):
    """
    åˆ›å»ºè®­ç»ƒå™¨
    
    Args:
        model: æ¨¡å‹
        tokenizer: åˆ†è¯å™¨
        train_dataset: è®­ç»ƒé›†
        eval_dataset: éªŒè¯é›†
        training_config: è®­ç»ƒé…ç½®
        data_collator: æ•°æ®æ•´ç†å‡½æ•°
        
    Returns:
        Trainer
    """
    # åˆ›å»ºè®­ç»ƒå‚æ•°
    training_args = create_training_arguments(training_config)
    
    # åˆ›å»ºè‡ªå®šä¹‰å›è°ƒ
    callback = CustomCallback(training_config.output_dir)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = RAFTTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        data_collator=data_collator,
        callbacks=[callback]
    )
    
    return trainer


def resume_training(trainer: Trainer, checkpoint_path: Optional[str] = None):
    """
    æ¢å¤è®­ç»ƒ
    
    Args:
        trainer: è®­ç»ƒå™¨
        checkpoint_path: æ£€æŸ¥ç‚¹è·¯å¾„
    """
    if checkpoint_path and os.path.exists(checkpoint_path):
        print(f"ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {checkpoint_path}")
        trainer.train(resume_from_checkpoint=checkpoint_path)
    else:
        print("å¼€å§‹æ–°çš„è®­ç»ƒ")
        trainer.train()


# æ–°å¢ï¼šè®­ç»ƒå¯è§†åŒ–å·¥å…·å‡½æ•°
def plot_training_curves(output_dir: str, save_path: Optional[str] = None):
    """
    ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    
    Args:
        output_dir: è®­ç»ƒè¾“å‡ºç›®å½•
        save_path: å›¾ç‰‡ä¿å­˜è·¯å¾„
    """
    try:
        import matplotlib.pyplot as plt
        import pandas as pd
        
        # è¯»å–è®­ç»ƒæŒ‡æ ‡
        metrics_file = os.path.join(output_dir, "training_metrics.json")
        if not os.path.exists(metrics_file):
            print(f"âŒ è®­ç»ƒæŒ‡æ ‡æ–‡ä»¶ä¸å­˜åœ¨: {metrics_file}")
            return
        
        with open(metrics_file, 'r', encoding='utf-8') as f:
            metrics = json.load(f)
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(metrics)
        
        # æ¸…ç†æ•°æ®
        df = df.dropna(subset=['train_loss'])
        
        # åˆ›å»ºå›¾è¡¨
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
        
        # ç»˜åˆ¶æŸå¤±æ›²çº¿
        if not df.empty:
            steps = df['step']
            
            # è®­ç»ƒæŸå¤±
            if 'train_loss' in df.columns:
                train_loss = df['train_loss'].dropna()
                if not train_loss.empty:
                    ax1.plot(steps[:len(train_loss)], train_loss, label='è®­ç»ƒæŸå¤±', color='blue', alpha=0.7)
            
            # è¯„ä¼°æŸå¤±
            if 'eval_loss' in df.columns:
                eval_loss = df['eval_loss'].dropna()
                if not eval_loss.empty:
                    ax1.plot(steps[:len(eval_loss)], eval_loss, label='è¯„ä¼°æŸå¤±', color='red', alpha=0.7)
            
            ax1.set_xlabel('è®­ç»ƒæ­¥æ•°')
            ax1.set_ylabel('æŸå¤±')
            ax1.set_title('è®­ç»ƒå’Œè¯„ä¼°æŸå¤±æ›²çº¿')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # ç»˜åˆ¶å­¦ä¹ ç‡æ›²çº¿
            if 'learning_rate' in df.columns:
                lr = df['learning_rate'].dropna()
                if not lr.empty:
                    ax2.plot(steps[:len(lr)], lr, label='å­¦ä¹ ç‡', color='green', alpha=0.7)
                    ax2.set_xlabel('è®­ç»ƒæ­¥æ•°')
                    ax2.set_ylabel('å­¦ä¹ ç‡')
                    ax2.set_title('å­¦ä¹ ç‡å˜åŒ–æ›²çº¿')
                    ax2.legend()
                    ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ“ è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ°: {save_path}")
        else:
            plt.show()
            
    except ImportError:
        print("âŒ è¯·å®‰è£…matplotlibå’Œpandasæ¥ç»˜åˆ¶è®­ç»ƒæ›²çº¿: pip install matplotlib pandas")
    except Exception as e:
        print(f"âŒ ç»˜åˆ¶è®­ç»ƒæ›²çº¿æ—¶å‡ºé”™: {e}")