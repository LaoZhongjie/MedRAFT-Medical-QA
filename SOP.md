# 🧠 Med-RAFT 项目整体流程

## 1. 数据收集与知识库构建

### 数据收集 （due Oct 18）
- 按病例搜集权威医学文档资料(PubMed)：
  - **呼吸系统（30%）**：感冒、肺炎、COPD、哮喘等  
  - **代谢 / 内分泌系统（25%）**：糖尿病、高血压等  
  - **消化系统（20%）**：胃炎、胃溃疡等  
  - **神经系统（15%）**：偏头痛等  
  - **其他（10%）**：支气管炎、荨麻疹等  

- 数据集：
  - (Lao)Huatuo-26M GitHub： https://github.com/FreedomIntelligence/Huatuo-26M 
  - (Lao)Huatuo26M-Lite（HuggingFace）： https://huggingface.co/datasets/FreedomIntelligence/Huatuo26M-Lite 
  - (Lao)WebMedQA： https://github.com/hejunqing/webMedQA 
  - (Wu)CMExam： https://github.com/williamliujl/CMExam 
  - (Wu)MLEC-QA： 论文地址 https://aclanthology.org/2021.emnlp-main.698/ （可跟论文里附带的数据链接） 
  - (Peng)PediaBench： https://github.com/ACMISLab/PediaBench 
  - (Peng)MedFact： https://github.com/AshleyChenNLP/MedFact

### 数据清洗 (due Oct 19)
- 去除重复、无效或不相关条目  
- 标准化文本格式  
- 处理中文编码问题  

### 知识库构建 (due Oct 19)
- 使用 **ChromaDB** 库将数据向量化  
- 简单测试检索功能，验证是否能准确返回相关文档  

### 准备教师模型输入数据 (due Oct 20)
- **Query**
  - 从真实 QA 数据集（如 *Huatuo-26M*）中提取问题  
  - 使用 LLM 生成模拟真实需求的问题  

- **Retriever**
  - 对 query 做 embedding  
  - 与所有文档块计算余弦相似度  
  - 取 Top-k（如 5）  
  - 手动或脚本判定：
    - 正确文档（**Oracle**）  
    - 干扰文档（**Distractors**）  
  - 若已有人工标注数据，可自动匹配包含正确答案的文档作为 Oracle  

---

## 2. 教师数据生成

### 提示工程（Prompt Engineering）
```
System: 你是一个有经验的中文医学专家（面向患者沟通）。在回答时必须提供清晰、分步的推理过程（可被当作教学示范），并引用提供的知识库证据。始终包含免责声明：本回答仅供参考，不能替代面对面医生诊断。若出现紧急或危及生命的症状，请立即就医。

User: 
你是一个经验丰富的中文医学专家，基于下面的知识库文档，回答患者的医学问题。要求严格遵守下列格式与规则。

输入：
- 问题: {患者原始问题文本}
- 知识库文档（按编号列出，每条包含“标题｜来源｜片段”）:
  [Doc1] 《中华结核和呼吸杂志》｜摘录片段：咳嗽持续3周以上，伴发热，需考虑结核病，建议胸部X光检查...
  [Doc2] ...
  （如果没有更多文档，只有 Doc1 也可）

要求（必须逐条满足）：
1. 用中文回答，语言清晰，适合一般患者理解（避免过度专业术语；如使用医学术语须在括号内简单解释）。
2. **输出格式严格按下面模板**（便于后续自动解析）：
   - 问题: {原问题}
   - 假设/已知信息: {把题目里明确的信息列点}
   - CoT推理（Step-by-step）: 
     1) {症状分析 — 每一步给出观察或依据}  
     2) {鉴别诊断 — 列出 2–4 个可能性，每项给出简短证据或反证理由}  
     3) {推荐检查 — 针对每个主要可能性给出优先检查项和原因}  
   - 初步诊断建议（含不确定度）: {例如“高度怀疑结核（置信度：中-高）”}  
   - 证据引用: {明确列出支持结论的知识库段落编号及简短摘录，例如 “[Doc1]：咳嗽持续3周以上，伴发热，需考虑结核病” }  
   - 不足信息与后续建议: {如果信息不足则写 “I don’t know” 并说明缺哪些信息；否则写需要进一步问诊的要点}  
   - 紧急就医指示（若有红旗症状）: {若无则写“无即刻红旗”}

3. 当信息不足以做出可信判断时，首句必须写 `I don’t know`，并紧接说明**缺哪些关键信息**（比如：痰中是否带血、夜间盗汗、体重下降、病程变化等），以及下一步要做的检查/问诊项。
4. 在 CoT 推理中**必须**引用知识库中相应段落作为证据（使用上面“证据引用”字段），不能引用未提供的外部资料。
5. 若问题涉及紧急情况（呼吸困难、呕血、晕厥等），优先给出紧急处理建议并提示立即就医。
6. 回答篇幅：CoT 控制在 4–8 步，每步不超过 2–3 行；整条回答控制在患者能在 2 分钟内读完的长度（约 200–350 字），但如必要可稍长以保证逻辑完整。
7. 语气：尊重、温和，避免绝对化用语（如“肯定”“一定”），用概率或置信度表示不确定性。

请基于上述规则回答下面的问题（严格使用上面“输出格式”）。
```

### 数据生成
- 从知识库中随机抽取 **1000 个文档块**  
- 生成 **1000 个问答对（Q&A）**  
- 确保覆盖多样化场景：
  - 单症状问题
  - 多症状问题
  - 罕见疾病  

### 质量检查
- 人工抽样检查 **100 个问答对**  
- 修正逻辑错误或幻觉问题  

**输出：**  
- 1000 个高质量问答对（包含 *问题 + Chain-of-Thought + 答案 + 引用*）

```
- 问题: 患者有发热和咳嗽3周，可能是什么疾病？

- 假设/已知信息:
  - 发热 + 咳嗽，持续时间约 3 周（来自问题）。
  - 已提供知识库： [Doc1] 《中华结核和呼吸杂志》：咳嗽持续3周以上，伴发热，需考虑结核病，建议胸部X光检查...

- CoT推理:
  1) 持续时间：咳嗽持续 ≥3 周提示不是短期上呼吸道感染，需考虑慢性或亚急性病因。  
  2) 伴随发热：发热提示有炎症或感染倾向，结合长期咳嗽需考虑结核、慢性细菌/真菌感染或肿瘤等。  
  3) 知识库依据：已有文献指出“咳嗽持续3周以上，伴发热，需考虑结核病”，因此结核是优先考虑项。  
  4) 鉴别要点：若伴有夜间盗汗、体重下降、痰中带血（咯血），更支持结核；若伴急性高热、脓性痰更可能细菌性肺炎；若长期吸烟且体重下降需警惕肺癌。  
  5) 检查建议（先后顺序）：首选胸部X光（排查肺部异常），如 X 光异常或高临床疑虑则做痰涂片/培养或结核核酸检测；必要时做胸部CT 与结核病专科会诊。

- 初步诊断建议（含不确定度）:
  - 初步高度怀疑：**结核病（置信度：中）**，需胸部影像学及痰学检查以确认/排除。

- 证据引用:
  - [Doc1]：《中华结核和呼吸杂志》 — “咳嗽持续3周以上，伴发热，需考虑结核病，建议胸部X光检查...”

- 不足信息与后续建议:
  - I don’t know。当前信息不足以确诊。缺失关键问诊/检查信息包括：痰是否带血、是否有夜间盗汗、体重变化、是否有结核接触史、既往疾病史、是否吸烟等。建议患者尽快做胸部X光并向呼吸科或结核专科就诊，带上痰标本做痰涂片/培养或核酸检测。

- 紧急就医指示（红旗）:
  - 若出现呼吸困难、咯血量大、持续高热或意识下降，请立即送急诊。
```

---

## 3. RAFT 数据集构建

**目标：** 为学生模型训练准备 RAFT 数据集，模拟检索增强任务。

### 文档匹配
- 为每个问题检索：
  - **Oracle 文档**：包含正确答案的 1–2 个文档块  
  - **Distractor 文档**：随机选取 3–4 个无关文档块  

### 样本构造
- 按 **80/20** 比例生成训练样本：
  - 80% 含 Oracle 文档（正样本）  
  - 20% 仅含 Distractor 文档（负样本，用于训练 “I don’t know” 能力）  
- 每个样本包含：
  - 问题（Question）  
  - 文档集（Oracle + Distractors）  
  - 教师答案（Teacher Answer）  

### 数据扩充
- 对部分样本添加噪声（如症状描述模糊）以增强鲁棒性  

**输出：**  
约 **800 个正样本 + 200 个负样本** 的 RAFT 数据集

---

## 4. 学生模型训练

### 模型与参数配置
- 模型：**LLaMA2-7B（4-bit 量化）**  
- 框架：**Hugging Face Transformers + PEFT (QLoRA)**  
- 参数设置：
  - `rank = 16`  
  - `alpha = 32`  
  - `dropout = 0.1`  
- 资源分配：16GB GPU（如 T4）

### 模型训练
- 批次大小：`batch_size = 4`  
- 梯度累积：`grad_accum = 4`  
- 学习率：`lr = 2e-4`  
- 训练轮数：3 轮  
- 记录每轮损失值与验证集表现  
- 中途检查（第 2 轮）可调整学习率或其他参数  

### 模型优化与保存
- 基于验证集 **BLEU / ROUGE** 指标选择最佳 checkpoint  
- 测试模型在 **无检索文档** 情况下的表现  
- 保存模型权重与训练日志  

---

## 5. 评估与推理管道

### 自动评估
- 测试集：50–100 个样本（含 Oracle + Distractor）  
- 指标要求：
  - BLEU-4 ≥ 0.30  
  - ROUGE-L ≥ 0.40  
  - BERTScore ≥ 0.60  
- 分析性能瓶颈与改进方向  

### 人工与性能评估
- 组织 2–3 名团队成员进行评审：
  - 医学准确性  
  - 回答相关性  
  - 安全性  
- 测试系统性能：
  - 响应延迟 < 5 秒  
  - 成功率 > 95%  
- 使用仅含 Distractor 文档的样本测试鲁棒性  

### 推理管道开发
- 使用 **Gradio** 搭建可视化界面  
- 集成 Fine-tuned 模型，实现：
  - 带文档推理  
  - 不带文档推理  
- 优化部署代码，确保 **Google Colab (T4)** 兼容性  

---

📦 **最终成果**
- 高质量医学知识库（结构化向量存储）  
- 1000 条教师问答数据  
- RAFT 数据集（800 正样本 + 200 负样本）  
- Fine-tuned 学生模型（LLaMA2-7B QLoRA）  
- 可交互推理界面（Gradio）
