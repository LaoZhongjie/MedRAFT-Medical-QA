# 🧠 Med-RAFT 项目整体流程

## 1. 数据收集与知识库构建

### 数据收集
按病例搜集权威医学文档资料：

- **呼吸系统（30%）**：感冒、肺炎、COPD、哮喘等  
- **代谢 / 内分泌系统（25%）**：糖尿病、高血压等  
- **消化系统（20%）**：胃炎、胃溃疡等  
- **神经系统（15%）**：偏头痛等  
- **其他（10%）**：支气管炎、荨麻疹等  

### 数据清洗
- 去除重复、无效或不相关条目  
- 标准化文本格式  
- 处理中文编码问题  

### 知识库构建
- 使用 **ChromaDB** 库将数据向量化  
- 测试检索功能，验证是否能准确返回相关文档  

### 准备教师模型输入数据
**Query**
- 从真实 QA 数据集（如 *Huatuo-26M*）中提取问题  
- 使用 LLM 生成模拟真实需求的问题  

**Retriever**
1. 对 query 做 embedding  
2. 与所有文档块计算余弦相似度  
3. 取 Top-k（如 5）  
4. 手动或脚本判定：
   - 正确文档（**Oracle**）  
   - 干扰文档（**Distractors**）  
5. 若已有人工标注数据，可自动匹配包含正确答案的文档作为 Oracle  

---

## 2. 教师数据生成

### 提示工程（Prompt Engineering）
设计提示以引导教师模型生成高质量答案。

### 数据生成
- 从知识库中随机抽取 **1000 个文档块**  
- 生成 **1000 个问答对（Q&A）**  
- 确保覆盖多样化场景：
  - 单症状问题
  - 多症状问题
  - 罕见疾病  

### 质量检查
- 人工抽样检查 **100 个问答对**  
- 修正逻辑错误或幻觉问题  

**输出：**  
1000 个高质量问答对（包含 *问题 + Chain-of-Thought + 答案 + 引用*）

---

## 3. RAFT 数据集构建

**目标：** 为学生模型训练准备 RAFT 数据集，模拟检索增强任务。

### 文档匹配
- 为每个问题检索：
  - **Oracle 文档**：包含正确答案的 1–2 个文档块  
  - **Distractor 文档**：随机选取 3–4 个无关文档块  

### 样本构造
- 按 **80/20** 比例生成训练样本：
  - 80% 含 Oracle 文档（正样本）  
  - 20% 仅含 Distractor 文档（负样本，用于训练 “I don’t know” 能力）  
- 每个样本包含：
  - 问题（Question）  
  - 文档集（Oracle + Distractors）  
  - 教师答案（Teacher Answer）  

### 数据扩充
- 对部分样本添加噪声（如症状描述模糊）以增强鲁棒性  

**输出：**  
约 **800 个正样本 + 200 个负样本** 的 RAFT 数据集

---

## 4. 学生模型训练

### 模型与参数配置
- 模型：**LLaMA2-7B（4-bit 量化）**  
- 框架：**Hugging Face Transformers + PEFT (QLoRA)**  
- 参数设置：
  - `rank = 16`  
  - `alpha = 32`  
  - `dropout = 0.1`  
- 资源分配：16GB GPU（如 T4）

### 模型训练
- 批次大小：`batch_size = 4`  
- 梯度累积：`grad_accum = 4`  
- 学习率：`lr = 2e-4`  
- 训练轮数：3 轮  
- 记录每轮损失值与验证集表现  
- 中途检查（第 2 轮）可调整学习率或其他参数  

### 模型优化与保存
- 基于验证集 **BLEU / ROUGE** 指标选择最佳 checkpoint  
- 测试模型在 **无检索文档** 情况下的表现  
- 保存模型权重与训练日志  

---

## 5. 评估与推理管道

### 自动评估
- 测试集：50–100 个样本（含 Oracle + Distractor）  
- 指标要求：
  - BLEU-4 ≥ 0.30  
  - ROUGE-L ≥ 0.40  
  - BERTScore ≥ 0.60  
- 分析性能瓶颈与改进方向  

### 人工与性能评估
- 组织 2–3 名团队成员进行评审：
  - 医学准确性  
  - 回答相关性  
  - 安全性  
- 测试系统性能：
  - 响应延迟 < 5 秒  
  - 成功率 > 95%  
- 使用仅含 Distractor 文档的样本测试鲁棒性  

### 推理管道开发
- 使用 **Gradio** 搭建可视化界面  
- 集成 Fine-tuned 模型，实现：
  - 带文档推理  
  - 不带文档推理  
- 优化部署代码，确保 **Google Colab (T4)** 兼容性  

---

📦 **最终成果**
- 高质量医学知识库（结构化向量存储）  
- 1000 条教师问答数据  
- RAFT 数据集（800 正样本 + 200 负样本）  
- Fine-tuned 学生模型（LLaMA2-7B QLoRA）  
- 可交互推理界面（Gradio）
